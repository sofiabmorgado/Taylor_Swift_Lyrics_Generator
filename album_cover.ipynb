{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taylor Swift's Cover Generator "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionPipeline\n",
    "import torch\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get summary of the lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'Cause baby, now we've got bad blood\n",
      "You know it used to be mad love, and you are the only one that can.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"generated_lyrics/generated_lyrics\", \"r\") as text_file:\n",
    "    generated_lyrics = text_file.read()\n",
    "\n",
    "print(generated_lyrics)\n",
    "\n",
    "\n",
    "#TODO: DELETE THIS!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "generated_lyrics_2 = \"\"\"You're on the phone with your girlfriend, she's upset\n",
    "She's going off about something that you said\n",
    "'Cause she doesn't get your humor like I do\n",
    "I'm in the room, it's a typical Tuesday night\n",
    "I'm listening to the kind of music she doesn't like\n",
    "And she'll never know your story like I do\n",
    "But she wears short skirts\n",
    "I wear T-shirts\n",
    "She's Cheer Captain, and I'm on the bleachers\n",
    "Dreaming about the day when you wake up and find\n",
    "That what you're looking for has been here the whole time\"\"\"\n",
    "\n",
    "#generated_lyrics = generated_lyrics_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': \"'Cause baby, now we've got bad blood. You know it used to be mad love, and you are the only one that\"}]\n"
     ]
    }
   ],
   "source": [
    "#BART is a neural network model that relies on bidirectional encoder and autoregressive decoder to encode the text and generate the summary. \n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "summary_list = summarizer(generated_lyrics, max_length=30, min_length=10, do_sample=False)\n",
    "print(summary_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Cause baby, now we've got bad blood. You know it used to be mad love, and you are the only one that\n"
     ]
    }
   ],
   "source": [
    "summary = summary_list[0][\"summary_text\"]\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate cover "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "text_encoder\\model.safetensors not found\n",
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n",
      "Loading pipeline components...:  29%|██▊       | 2/7 [00:01<00:03,  1.31it/s]`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
      "Loading pipeline components...: 100%|██████████| 7/7 [00:54<00:00,  7.81s/it]\n"
     ]
    }
   ],
   "source": [
    "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [31:49<00:00, 38.20s/it]\n"
     ]
    }
   ],
   "source": [
    "image = pipe(summary).images[0]  \n",
    "image.save(\"cover_album/album_cover.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "https://huggingface.co/runwayml/stable-diffusion-v1-5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
